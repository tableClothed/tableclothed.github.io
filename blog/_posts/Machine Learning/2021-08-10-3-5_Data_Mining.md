---
layout: post
title:  "Data Mining"
date:   2021-04-23 16:10:35 +0100
categories: 
- machine learning
description: "Data Mining in Python with focus on machine learning algorithms and techniques. K-Nearest Neighbors (KNN), Principal Component Analysis (PCA)."
image: 'images/posts/datamining/1.png'

---
### K-Nearest Neighbor (KNN)

Used to classify new data points based on "distance" to known data

Find the K nearest neighbors, based on your distance metrics

Let them all vote on the classification

<center>
<img src="/images/posts/datamining/1.png">
</center>


<center>
<img src="/images/posts/datamining/2.png">
</center>


```python
import pandas as pd
import numpy as np
import os

r_cols = ["user_id", "movie_id", "rating"]
df = pd.read_csv("data/ml-100k/u.data", sep="\t", names=r_cols, usecols=range(3))
df.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>user_id</th>
      <th>movie_id</th>
      <th>rating</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>50</td>
      <td>5</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>172</td>
      <td>5</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>133</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>196</td>
      <td>242</td>
      <td>3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>186</td>
      <td>302</td>
      <td>3</td>
    </tr>
  </tbody>
</table>
</div>




```python
movieProperties = df.groupby("movie_id").agg({"rating":[np.size, np.mean]})
movieProperties.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }

    .dataframe thead tr:last-of-type th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th colspan="2" halign="left">rating</th>
    </tr>
    <tr>
      <th></th>
      <th>size</th>
      <th>mean</th>
    </tr>
    <tr>
      <th>movie_id</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>452</td>
      <td>3.878319</td>
    </tr>
    <tr>
      <th>2</th>
      <td>131</td>
      <td>3.206107</td>
    </tr>
    <tr>
      <th>3</th>
      <td>90</td>
      <td>3.033333</td>
    </tr>
    <tr>
      <th>4</th>
      <td>209</td>
      <td>3.550239</td>
    </tr>
    <tr>
      <th>5</th>
      <td>86</td>
      <td>3.302326</td>
    </tr>
  </tbody>
</table>
</div>




```python
movieNumRatings = pd.DataFrame(movieProperties["rating"]["size"])
movieNormalizedRatings = movieNumRatings.apply(lambda x: ( x - np.min(x)) / (np.max(x) - np.min(x)))
movieNormalizedRatings.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>size</th>
    </tr>
    <tr>
      <th>movie_id</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>0.773585</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.222985</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.152659</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.356775</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.145798</td>
    </tr>
  </tbody>
</table>
</div>




```python
movieDict = {}
with open("data/ml-100k/u.item") as f:
    temp = ''
    for line in f:
        fields = line.rstrip('\n').split('|')
        movieID = int(fields[0])
        name = fields[1]
        genres = fields[5:25]
        genres = map(int, genres)
        movieDict[movieID] = (name,
                              np.array(list(genres)),
                              movieNormalizedRatings.loc[movieID].get("size"),
                              movieProperties.loc[movieID].rating.get("mean"))
```


```python
movieDict[1]
```




    ('Toy Story (1995)',
     array([0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),
     0.7735849056603774,
     3.8783185840707963)




```python
from scipy import spatial

def ComputeDistance(a, b):
    genresA = a[1]
    genresB = b[1]    
    genreDistance = spatial.distance.cosine(genresA, genresB)
    popularityA = a[2]
    popularityB = b[2]
    popularityDistance = abs(popularityA - popularityB)
    return genreDistance + popularityDistance
```


```python
ComputeDistance(movieDict[2], movieDict[4])
```




    0.8004574042309892




```python
import operator

def getNeighbors(movieID, K):
    distances = []
    for movie in movieDict:
        if movie != movieID:
            dist = ComputeDistance(movieDict[movieID], movieDict[movie])
            distances.append((movie, dist))
    distances.sort(key=operator.itemgetter(1))
    neighbors = []
    for x in range(K):
        neighbors.append(distances[x][0])
    return neighbors
```


```python
K = 10
avgRating = 0
neighbors = getNeighbors(1, K)
for neighbor in neighbors:
    avgRating += movieDict[neighbor][3]
    print(movieDict[neighbor][0] + " " + str(movieDict[neighbor][3]))
```

    Liar Liar (1997) 3.156701030927835
    Aladdin (1992) 3.8127853881278537
    Willy Wonka and the Chocolate Factory (1971) 3.6319018404907975
    Monty Python and the Holy Grail (1974) 4.0664556962025316
    Full Monty, The (1997) 3.926984126984127
    George of the Jungle (1997) 2.685185185185185
    Beavis and Butt-head Do America (1996) 2.7884615384615383
    Birdcage, The (1996) 3.4436860068259385
    Home Alone (1990) 3.0875912408759123
    Aladdin and the King of Thieves (1996) 2.8461538461538463
    


```python
avgRating /= float(K)
avgRating
```




    3.3445905900235564




```python
movieDict[1]
```




    ('Toy Story (1995)',
     array([0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),
     0.7735849056603774,
     3.8783185840707963)



### Principal Component Analysis

PCA is a dimensionality reduction technique; it lets you distill multi-dimensional data down to fewer dimensions, selecting new dimensions.


```python
from sklearn.datasets import load_iris
from sklearn.decomposition import PCA
import pylab as pl
from itertools import cycle

iris = load_iris()

numSamples, numFeatures = iris.data.shape
numSamples, numFeatures
```




    (150, 4)




```python
list(iris.target_names)
```




    ['setosa', 'versicolor', 'virginica']




```python
X = iris.data
pca = PCA(n_components=2, whiten=True).fit(X)
X_pca = pca.transform(X)
```


```python
pca.components_
```




    array([[ 0.36138659, -0.08452251,  0.85667061,  0.3582892 ],
           [ 0.65658877,  0.73016143, -0.17337266, -0.07548102]])




```python
pca.explained_variance_ratio_
```




    array([0.92461872, 0.05306648])




```python
sum(pca.explained_variance_ratio_)
```




    0.9776852063187949




```python
colors = cycle("rgb")
target_ids = range(len(iris.target_names))
pl.figure()
for i, c, label in zip(target_ids, colors, iris.target_names):
    pl.scatter(X_pca[iris.target == i, 0], X_pca[iris.target == i, 1],
    c=c, label=label)
pl.legend()
pl.show()
```


![png](images/posts/datamining/output_23_0.png)
